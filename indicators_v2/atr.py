import logging
import pandas as pd
import json
from datetime import datetime
from statistics import median
from debug_utils import debug_log

# üî∏ –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–æ—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ 100 –ø–æ—Å–ª–µ–¥–Ω–∏—Ö)
async def cleanup_old_values(db, instance_id, symbol, param_name):
    try:
        async with db.acquire() as conn:
            await conn.execute(
                """
                DELETE FROM indicator_values_v2
                WHERE ctid IN (
                    SELECT ctid FROM (
                        SELECT ctid,
                               ROW_NUMBER() OVER (
                                   PARTITION BY instance_id, symbol, param_name
                                   ORDER BY open_time DESC
                               ) AS rownum
                        FROM indicator_values_v2
                        WHERE instance_id = $1 AND symbol = $2 AND param_name = $3
                    ) sub
                    WHERE sub.rownum > 300
                )
                """,
                instance_id, symbol, param_name
            )
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ ATR {param_name} –¥–ª—è {symbol}: {e}")

# üî∏ –†–∞—Å—á—ë—Ç ATR –∏ median(30) –ø–æ ATR (–∏–∑ –±–∞–∑—ã)
async def process_atr(instance_id, symbol, tf, open_time, params, candles, redis, db, precision_price, stream_publish):
    try:
        length = int(params.get("length", 14))

        if not all(col in candles.columns for col in ("high", "low", "close")):
            logging.warning(f"‚ö†Ô∏è –ù–µ—Ç high/low/close –≤ —Å–≤–µ—á–∞—Ö {symbol} / {tf}")
            return

        high = candles["high"].astype(float)
        low = candles["low"].astype(float)
        close = candles["close"].astype(float)
        prev_close = close.shift(1)

        tr = pd.concat([
            (high - low).abs(),
            (high - prev_close).abs(),
            (low - prev_close).abs()
        ], axis=1).max(axis=1)

        atr_series = tr.ewm(alpha=1/length, adjust=False).mean()
        atr_value = round(float(atr_series.iloc[-1]), precision_price)

        redis_key = f"{symbol}:{tf}:ATR:{length}"
        await redis.set(redis_key, atr_value)

        open_dt = datetime.fromisoformat(open_time)
        param_name = f"atr{length}"

        # üîπ –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–∫—É—â–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ATR –≤ –ë–î
        async with db.acquire() as conn:
            await conn.execute(
                """
                INSERT INTO indicator_values_v2
                (instance_id, symbol, open_time, param_name, value)
                VALUES ($1, $2, $3, $4, $5)
                ON CONFLICT DO NOTHING
                """,
                instance_id, symbol, open_dt, param_name, atr_value
            )

        # üîπ –û—á–∏—Å—Ç–∫–∞ –ª–∏—à–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        await cleanup_old_values(db, instance_id, symbol, param_name)

        debug_log(f"‚úÖ ATR{length} –¥–ª—è {symbol} / {tf} = {atr_value}")

        # üîπ –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 30 –∑–Ω–∞—á–µ–Ω–∏–π ATR –∏–∑ –ë–î
        async with db.acquire() as conn:
            rows = await conn.fetch(
                """
                SELECT value
                FROM indicator_values_v2
                WHERE instance_id = $1
                  AND symbol = $2
                  AND param_name = $3
                ORDER BY open_time DESC
                LIMIT 30
                """,
                instance_id, symbol, param_name
            )

        values = [float(row["value"]) for row in rows if row["value"] is not None]

        if len(values) >= 3:
            median_val = round(median(values), precision_price)
            median_key = f"{symbol}:{tf}:ATR:median_30"
            await redis.set(median_key, median_val)
            debug_log(f"üìä median(30) –ø–æ ATR: {symbol} / {tf} = {median_val}")
        else:
            logging.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è median(30) ATR {symbol} / {tf}")

        if stream_publish:
            try:
                await redis.xadd(
                    "indicators_ready_stream",
                    {
                        "symbol": symbol,
                        "timeframe": tf,
                        "indicator": "ATR",
                        "params": json.dumps({"length": str(length)}),
                        "calculated_at": open_time
                    }
                )
                debug_log(f"üì§ Stream: ATR{length} –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω –¥–ª—è {symbol} / {tf}")
            except Exception as e:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—É–±–ª–∏–∫–∞—Ü–∏–∏ ATR –≤ Redis Stream: {e}")

    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞—Å—á—ë—Ç–∞ ATR {symbol} / {tf}: {e}")